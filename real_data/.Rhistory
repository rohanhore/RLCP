smoker_coverage=cbind(coverage_smoker_lm_RLCP,coverage_smoker_lm_calLCP,coverage_smoker_lm_baseLCP,
coverage_smoker_rf_RLCP,coverage_smoker_rf_calLCP,coverage_smoker_rf_baseLCP,
coverage_smoker_nn_RLCP,coverage_smoker_nn_calLCP,coverage_smoker_nn_baseLCP)
))
}
library(doParallel)
numcores=detectCores()-1
cl=makeCluster(numcores)
registerDoParallel(cl)
#bandwidth choices
hseq=2:8
real_result=vector('list',length=length(hseq))
mc=width=matrix(0,nrow=length(hseq),ncol=9)
comb=function(x,y){return(list(rbind(x[[1]],y[[1]]),x[[2]]+y[[2]],x[[3]]+y[[3]],
x[[4]]+y[[4]]))}
nrep=100
for(i in 1:length(hseq)){
h=hseq[i]
print(h)
result_h=foreach(k=1:nrep,.combine=comb,
.packages = c("MASS","parallel","doParallel",
"foreach","mvtnorm","randomForest",
"neuralnet")) %dopar% {
real_analysis(h,k)
}
result_h=lapply(result_h,FUN=function(x) x/nrep)
real_result[[i]]=result_h
print(colMeans(real_result[[i]][[1]]*nrep))
width[i,]=real_result[[i]][[2]]
}
stopCluster(cl)
#----------------marginal coverage------------------
plot_result=matrix(0,ncol=5,nrow=9*length(hseq))
for(i in 1:length(hseq)){
id=(9*(i-1)+1):(9*i)
res=stack(as.data.frame(apply(real_result[[i]][[1]]*nrep,2,mean)))
plot_result[id,1]=res[,1]
plot_result[id,2]=rep(c("RLCP","calLCP","baseLCP"),3)
plot_result[id,3]=rep(c("Linear Model","Random Forest","Neural Net"),each=3)
plot_result[id,4]=hseq[i]
plot_result[id,5]=stack(as.data.frame(apply(real_result[[i]][[1]]*nrep,2,sd)))[,1]/sqrt(nrep)
}
plot_result=as.data.frame(plot_result)
colnames(plot_result)=c("coverage","CP_method","base_method","h","se")
plot_result$coverage=as.numeric(plot_result$coverage)
plot_result$h=as.numeric(plot_result$h)
plot_result$se=as.numeric(plot_result$se)
plot_result$CP_method=factor(plot_result$CP_method,level=c('baseLCP','calLCP','RLCP'))
plot1=ggplot(plot_result, aes(x=h, y = coverage, color=CP_method)) +
geom_line() +
geom_point()+
ylim(0.88,0.98)+
geom_errorbar(aes(ymin=coverage-se, ymax=coverage+se), width=.02,
position=position_dodge(0.01))+
geom_hline(yintercept=0.9,linetype="dashed")+
scale_color_manual(values=c("RLCP"="maroon","calLCP"="gold3","baseLCP"="blue"))+
facet_grid(.~base_method)+
scale_x_continuous(n.breaks=3)+
theme(legend.position = "none")+
labs(color="Method",x="Bandwidth h",y="Coverage")
#--------------------PI widths------------------------------
write.csv(round(t(width),2),"../results/real_data_width.csv")
plot_result=matrix(0,ncol=4,nrow=9*length(hseq))
for(i in 1:length(hseq)){
id=(9*(i-1)+1):(9*i)
res=stack(as.data.frame(real_result[[i]][[2]]))
plot_result[id,1]=res[,1]
plot_result[id,2]=rep(c("RLCP","calLCP","baseLCP"),3)
plot_result[id,3]=rep(c("Linear Model","Random Forest","Neural Net"),each=3)
plot_result[id,4]=hseq[i]
}
plot_result=as.data.frame(plot_result)
colnames(plot_result)=c("width","CP_method","base_method","h")
plot_result$width=as.numeric(plot_result$width)
plot_result$h=as.numeric(plot_result$h)
plot_result$CP_method=factor(plot_result$CP_method,level=c('baseLCP','calLCP','RLCP'))
plot2=ggplot(plot_result, aes(x=h, y = width, color=CP_method)) +
geom_line() +
geom_point()+
ylim(0.5,2.5)+
scale_x_continuous(n.breaks=3)+
scale_color_manual(values=c("RLCP"="maroon","calLCP"="gold3","baseLCP"="blue"))+
facet_grid(.~base_method)+
labs(color="Method",x="Bandwidth h",y="Prediction interval width")
pdf(file = "../results/realdata_marginal_results.pdf",width = 9, height = 4)
grid.arrange(plot1,plot2,ncol=2,widths=c(2.6,3))
dev.off()
grid.arrange(plot1,plot2,ncol=2,widths=c(2.6,3))
smoker_cov=matrix(0,nrow=2*length(hseq),ncol=9)
for(i in 1:length(hseq)){
smoker_cov[(2*(i-1)+1):(2*i),]=matrix(unlist(real_result[[i]][5]),nrow=2,byrow=F)
}
write.csv(smoker_cov,"../results/real_data_smoker_cov.csv")
smoker_cov=matrix(0,nrow=2*length(hseq),ncol=9)
for(i in 1:length(hseq)){
smoker_cov[(2*(i-1)+1):(2*i),]=matrix(unlist(real_result[[i]][4]),nrow=2,byrow=F)
}
write.csv(smoker_cov,"../results/real_data_smoker_cov.csv")
#---------------across smoking groups------------------
plot_result=matrix(0,ncol=5,nrow=2*9*length(hseq))
for(i in 1:length(hseq)){
id=(2*9*(i-1)+1):(2*9*i)
res=stack(as.data.frame(real_result[[i]][[4]]))
plot_result[id,1]=res[,1]
plot_result[id,2]=rep(rep(c("RLCP","calLCP","baseLCP"),each=2),3)
plot_result[id,3]=rep(c("Linear Model","Random Forest","Neural Net"),each=2*3)
plot_result[id,4]=rep(c(0,1),9)
plot_result[id,5]=hseq[i]
}
plot_result=as.data.frame(plot_result)
colnames(plot_result)=c("coverage","CP_method","base method","smoker","h")
plot_result$coverage=as.numeric(plot_result$coverage)
plot_result$h=as.numeric(plot_result$h)
plot_result$CP_method=factor(plot_result$CP_method,level=c('baseLCP','calLCP','RLCP'))
plot3=ggplot(plot_result[plot_result$h %in% c(2,6),], aes(x = CP_method, y = coverage,group=smoker,
fill=smoker)) +
geom_col(position='dodge',width=0.5) +
coord_cartesian(ylim=c(0.8,1))+
xlab("LCP method")+
scale_fill_discrete(labels=c("0"="no","1"="yes"))+
geom_hline(yintercept=0.9,linetype="dashed")+
facet_grid(h~`base method`,labeller = label_bquote(cols = .(`base method`),rows= h ==.(h)))+
theme(legend.position = "bottom")+
labs(fill="Smoker",x="Method",y="Coverage")
#-------------across BMI bins-------------------------
bmi_quantiles=seq(0.125,0.875,by=0.01);len_q=length(bmi_quantiles)
plot_result=matrix(0,ncol=5,nrow=len_q*9*length(hseq))
for(i in 1:length(hseq)){
id=(len_q*9*(i-1)+1):(len_q*9*i)
res=stack(as.data.frame(real_result[[i]][[3]]))
plot_result[id,1]=res[,1]
plot_result[id,2]=rep(rep(c("RLCP","calLCP","baseLCP"),each=len_q),3)
plot_result[id,3]=rep(c("Linear Model","Random Forest","Neural Net"),each=len_q*3)
plot_result[id,4]=rep(bmi_quantiles,9)
plot_result[id,5]=hseq[i]
}
plot_result=as.data.frame(plot_result)
colnames(plot_result)=c("coverage","CP_method","base method","bmi","h")
plot_result$coverage=as.numeric(plot_result$coverage)
plot_result$bmi=as.numeric(plot_result$bmi)
plot_result$h=as.numeric(plot_result$h)
plot_result$CP_method=factor(plot_result$CP_method,level=c('baseLCP','calLCP','RLCP'))
plot4=ggplot(plot_result[plot_result$h %in% c(2,6),], aes(x = bmi, y = coverage,color=CP_method)) +
geom_line() +
geom_hline(yintercept=0.9,linetype="dashed")+
xlab("BMI quantile")+
scale_color_manual(values=c("RLCP"="maroon","calLCP"="gold3","baseLCP"="blue"))+
facet_grid(h~ `base method` ,labeller=label_bquote(cols = .(`base method`),rows= h ==.(h)))+
theme(legend.position = "bottom")+
labs(color="Method",x="BMI Quantile",y="Local Coverage")
grid.arrange(plot3,plot4,ncol=2,widths=c(2.6,3))
pdf(file = "/Users/rohanhore/Dropbox/My projects/rLCP/Results/realdata_conditional_results.pdf",width = 13, height = 5)
grid.arrange(plot3,plot4,ncol=2,widths=c(2.6,3))
dev.off()
pdf(file = "../results/figures/realdata_conditional_results.pdf",width = 13, height = 5)
grid.arrange(plot3,plot4,ncol=2,widths=c(2.6,3))
dev.off()
pdf(file = "../results/figures/realdata_marginal_results.pdf",width = 9, height = 4)
grid.arrange(plot1,plot2,ncol=2,widths=c(2.6,3))
dev.off()
pdf(file = "../results/figures/realdata_marginal_results.pdf",width = 12, height = 3)
grid.arrange(plot1,plot2,ncol=2,widths=c(2.6,3))
dev.off()
pdf(file = "../results/figures/realdata_marginal_results.pdf",width = 10, height = 3)
grid.arrange(plot1,plot2,ncol=2,widths=c(2.6,3))
dev.off()
#---------------------------------------------------
#-------------------source code---------------------
#---------------------------------------------------
source("../utils/simu_sett.R")
source("../utils/methods.R")
#---------------------------------------------------
#------------------load libraries-------------------
#---------------------------------------------------
suppressPackageStartupMessages(library(doParallel))
suppressPackageStartupMessages(library(MASS))
suppressPackageStartupMessages(library(mvtnorm))
suppressPackageStartupMessages(library(randomForest))
suppressPackageStartupMessages(library(neuralnet))
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(gridExtra))
suppressPackageStartupMessages(library(ggplot2))
#--------------------------------------------------------
#--------data loading & pre-processing-------------------
#--------------------------------------------------------
data=read.csv("/Users/rohanhore/Dropbox/My projects/rLCP/Data/Insurance Dataset/Train_Data.csv",header=T)
data=as.data.frame(data)
data=data %>% distinct()
#disregarding the children and region information
data=data[,-c(5,6)]
#log transformation on insurance charges
data[,5]=log(data[,5])
n=dim(data)[1]
data$sex=as.factor(data$sex);data$smoker=as.factor(data$smoker)
data$smoker=dplyr::recode_factor(data$smoker,"yes" = "1","no" = "0")
data$sex=dplyr::recode_factor(data$sex,"male" = "1","female" = "0")
attach(data);sex=as.factor(sex);smoker=as.factor(smoker)
#scaling data for neural nets
scaled_data=data
min_age=min(scaled_data[,1]);max_age=max(scaled_data[,1])
min_bmi=min(scaled_data[,3]);max_bmi=max(scaled_data[,3])
scaled_data[,1]=(scaled_data[,1]-min_age)/(max_age-min_age)
scaled_data[,3]=(scaled_data[,3]-min_bmi)/(max_bmi-min_bmi)
min_charge=min(scaled_data[,5]);max_charge=max(scaled_data[,5])
scaled_data[,5]=(scaled_data[,5]-min_charge)/(max_charge-min_charge)
dmy=dummyVars(" ~ .", data = scaled_data)
scaled_data <- data.frame(predict(dmy, newdata = scaled_data))
RLCP_real=function(Xcalib,scores_calib,Xtest,scores_test,h,alpha){
ntest=dim(Xtest)[1];d=dim(Xtest)[2]
coverage=threshold=rep(0,ntest)
Xcalib=as.matrix(Xcalib[order(scores_calib),]);scores_calib=sort(scores_calib)
scores=c(scores_calib,Inf)
indices=list();j=1;i=1
scores_unique=vector()
while(i<=length(scores)){
scores_unique=c(scores_unique,scores[i])
indices[[j]]=which(scores==scores[i])
i=i+length(indices[[j]]);j=j+1
}
for(i in 1:ntest){
xtest=Xtest[i,];test_score=scores_test[i]
xtilde_test=xtest
xtilde_test[c(1,3)]=xtest[c(1,3)]+runif(2,min=-h,max=h)
cov_data=rbind(Xcalib,xtest)
weights=apply(abs(sweep(cov_data,2,as.numeric(xtilde_test),"-")),1,FUN=function(x) all(x<=c(h,0,h,0))+0)
result=smoothed_weighted_quantile(scores_unique,alpha,weights,indices)
threshold[i]=result[1]
closed=result[2]
coverage[i]=(test_score<threshold[i])+0
if(closed==TRUE){coverage[i]=(test_score<=threshold[i])+0}
}
return(cbind(coverage,threshold))
}
#--------------------------------------------------------------
#---------------computing deviation of RLCP PI-----------------
#--------------------------------------------------------------
real_RLCP_deviation=function(h,k,split){
train_data=data[split==1,];ntrain=dim(train_data)[1]
calib_data=data[split==2,];ncalib=dim(calib_data)[1]
test_data=data[split==3,];ntest=dim(test_data)[1]
train_scaled_data=scaled_data[split==1,]
calib_scaled_data=scaled_data[split==2,]
test_scaled_data=scaled_data[split==3,]
#------------learning score on train split-------------------------
Xcalib=calib_data[,1:4];Xcalib[,2]=as.numeric(Xcalib[,2]);Xcalib[,4]=as.numeric(Xcalib[,4])
Xtest=test_data[,1:4];Xtest[,2]=as.numeric(Xtest[,2]);Xtest[,4]=as.numeric(Xtest[,4])
#---linear model---------
model_lm=lm(charges~.,data=train_data)
predict_lm_test=predict(model_lm,newdata=test_data)
scores_lm_calib=abs(calib_data$charges-predict.lm(model_lm,calib_data))
scores_lm_test=abs(test_data$charges-predict.lm(model_lm,test_data))
result_lm_RLCP=RLCP_real(Xcalib, scores_lm_calib,Xtest,scores_lm_test,h,0.1)
#result_lm_RLCP[result_lm_RLCP[,2]==Inf,2]=scores_lm_calib
width_lm_RLCP=2*result_lm_RLCP[,2]
#----random forest----------
model_rf=randomForest(charges ~ .,data=train_data)
predict_rf_test=predict(model_rf,newdata=test_data)
scores_rf_calib=abs(calib_data$charges-predict(model_rf,calib_data))
scores_rf_test=abs(test_data$charges-predict(model_rf,test_data))
result_rf_RLCP=RLCP_real(Xcalib, scores_rf_calib,Xtest,scores_rf_test,h,0.1)
width_rf_RLCP=2*result_rf_RLCP[,2]
#----------neural net--------------------
model_nn=neuralnet(charges~.,data = train_scaled_data, hidden = c(5, 3),
threshold=0.05,linear.output = TRUE)
predict_nn_calib=compute(model_nn,calib_scaled_data[,1:6])$net.result*
(max_charge-min_charge)+min_charge
predict_nn_test=compute(model_nn,test_scaled_data[,1:6])$net.result*
(max_charge-min_charge)+min_charge
scores_nn_calib=abs(calib_data$charges-predict_nn_calib)
scores_nn_test=abs(test_data$charges-predict_nn_test)
result_nn_RLCP=RLCP_real(Xcalib,scores_nn_calib,Xtest,scores_nn_test,h,0.1)
width_nn_RLCP=as.vector(2*result_nn_RLCP[,2])
return(list(width_lm_RLCP,width_rf_RLCP,width_nn_RLCP))
}
real_RLCP_deviation(h,l,split)
h=2
l=1
split=sample(1:3,n,replace=TRUE,prob=c(1/3,1/3,1/3))
n
real_RLCP_deviation(h,l,split)
train_data=data[split==1,];ntrain=dim(train_data)[1]
calib_data=data[split==2,];ncalib=dim(calib_data)[1]
test_data=data[split==3,];ntest=dim(test_data)[1]
train_scaled_data=scaled_data[split==1,]
calib_scaled_data=scaled_data[split==2,]
test_scaled_data=scaled_data[split==3,]
#------------learning score on train split-------------------------
Xcalib=calib_data[,1:4];Xcalib[,2]=as.numeric(Xcalib[,2]);Xcalib[,4]=as.numeric(Xcalib[,4])
Xtest=test_data[,1:4];Xtest[,2]=as.numeric(Xtest[,2]);Xtest[,4]=as.numeric(Xtest[,4])
#---linear model---------
model_lm=lm(charges~.,data=train_data)
predict_lm_test=predict(model_lm,newdata=test_data)
scores_lm_calib=abs(calib_data$charges-predict.lm(model_lm,calib_data))
scores_lm_test=abs(test_data$charges-predict.lm(model_lm,test_data))
result_lm_RLCP=RLCP_real(Xcalib, scores_lm_calib,Xtest,scores_lm_test,h,0.1)
#result_lm_RLCP[result_lm_RLCP[,2]==Inf,2]=scores_lm_calib
width_lm_RLCP=2*result_lm_RLCP[,2]
#----random forest----------
model_rf=randomForest(charges ~ .,data=train_data)
width_lm_RLCP
#----------neural net--------------------
model_nn=neuralnet(charges~.,data = train_scaled_data, hidden = c(5, 3),
threshold=0.05,linear.output = TRUE)
predict_nn_calib=compute(model_nn,calib_scaled_data[,1:6])$net.result*
(max_charge-min_charge)+min_charge
predict_nn_test=compute(model_nn,test_scaled_data[,1:6])$net.result*
(max_charge-min_charge)+min_charge
#----------neural net--------------------
model_nn=neuralnet(charges~.,data = train_scaled_data, hidden = c(5, 3),
threshold=0.05,linear.output = TRUE)
#----------neural net--------------------
model_nn=neuralnet(charges~.,data = train_scaled_data, hidden = c(5, 3),
threshold=0.05,linear.output = TRUE)
predict_nn_calib=neuralnet::compute(model_nn,calib_scaled_data[,1:6])$net.result*
(max_charge-min_charge)+min_charge
predict_nn_test=neuralnet::compute(model_nn,test_scaled_data[,1:6])$net.result*
(max_charge-min_charge)+min_charge
scores_nn_calib=abs(calib_data$charges-predict_nn_calib)
scores_nn_test=abs(test_data$charges-predict_nn_test)
result_nn_RLCP=RLCP_real(Xcalib,scores_nn_calib,Xtest,scores_nn_test,h,0.1)
width_nn_RLCP=as.vector(2*result_nn_RLCP[,2])
width_nn_RLCP
abs(-2)
#--------------------------------------------------------------
#---------------computing deviation of RLCP PI-----------------
#--------------------------------------------------------------
real_RLCP_deviation=function(h,k,split){
train_data=data[split==1,];ntrain=dim(train_data)[1]
calib_data=data[split==2,];ncalib=dim(calib_data)[1]
test_data=data[split==3,];ntest=dim(test_data)[1]
train_scaled_data=scaled_data[split==1,]
calib_scaled_data=scaled_data[split==2,]
test_scaled_data=scaled_data[split==3,]
#------------learning score on train split-------------------------
Xcalib=calib_data[,1:4];Xcalib[,2]=as.numeric(Xcalib[,2]);Xcalib[,4]=as.numeric(Xcalib[,4])
Xtest=test_data[,1:4];Xtest[,2]=as.numeric(Xtest[,2]);Xtest[,4]=as.numeric(Xtest[,4])
#---linear model---------
model_lm=lm(charges~.,data=train_data)
predict_lm_test=predict(model_lm,newdata=test_data)
scores_lm_calib=abs(calib_data$charges-predict.lm(model_lm,calib_data))
scores_lm_test=abs(test_data$charges-predict.lm(model_lm,test_data))
result_lm_RLCP=RLCP_real(Xcalib, scores_lm_calib,Xtest,scores_lm_test,h,0.1)
#result_lm_RLCP[result_lm_RLCP[,2]==Inf,2]=scores_lm_calib
width_lm_RLCP=2*abs(result_lm_RLCP[,2])
#----random forest----------
model_rf=randomForest(charges ~ .,data=train_data)
predict_rf_test=predict(model_rf,newdata=test_data)
scores_rf_calib=abs(calib_data$charges-predict(model_rf,calib_data))
scores_rf_test=abs(test_data$charges-predict(model_rf,test_data))
result_rf_RLCP=RLCP_real(Xcalib, scores_rf_calib,Xtest,scores_rf_test,h,0.1)
width_rf_RLCP=2*abs(result_rf_RLCP[,2])
#----------neural net--------------------
model_nn=neuralnet(charges~.,data = train_scaled_data, hidden = c(5, 3),
threshold=0.05,linear.output = TRUE)
predict_nn_calib=neuralnet::compute(model_nn,calib_scaled_data[,1:6])$net.result*
(max_charge-min_charge)+min_charge
predict_nn_test=neuralnet::compute(model_nn,test_scaled_data[,1:6])$net.result*
(max_charge-min_charge)+min_charge
scores_nn_calib=abs(calib_data$charges-predict_nn_calib)
scores_nn_test=abs(test_data$charges-predict_nn_test)
result_nn_RLCP=RLCP_real(Xcalib,scores_nn_calib,Xtest,scores_nn_test,h,0.1)
width_nn_RLCP=as.vector(2*abs(result_nn_RLCP[,2]))
return(list(width_lm_RLCP,width_rf_RLCP,width_nn_RLCP))
}
#--------------------------------------------------------------
#----------------------experimental results--------------------
#--------------------------------------------------------------
library(doParallel)
numcores=detectCores()
cl=makeCluster(numcores)
registerDoParallel(cl)
#bandwidth choices
hseq=2:8
comb_rand=function(x,y){return(list(rbind(x[[1]],y[[1]]),rbind(x[[2]],y[[2]]),rbind(x[[3]],y[[3]])))}
result_rand=matrix(0,ncol=length(hseq),nrow=3)
for(i in 1:length(hseq)){
h=hseq[i]
print(h)
result_h=rep(0,3)
start=Sys.time()
for(k in 1:20){
split=sample(1:3,n,replace=TRUE,prob=c(1/3,1/3,1/3))
result_split=foreach(l=1:30,.combine=comb_rand,
.packages = c("MASS","parallel","doParallel",
"foreach","mvtnorm","randomForest",
"neuralnet")) %dopar% {
real_RLCP_deviation(h,l,split)
}
#computing deviation of the PI across several random seeds
deviation=function(x){median(abs(x-median(x)))/median(x)}
width_lm_RLCP=result_split[[1]]
width_rf_RLCP=result_split[[2]]
width_nn_RLCP=result_split[[3]]
dev_lm=mean(apply(width_lm_RLCP[,apply(width_lm_RLCP,2,median)!=Inf],2,deviation))
dev_rf=mean(apply(width_rf_RLCP[,apply(width_rf_RLCP,2,median)!=Inf],2,deviation))
dev_nn=mean(apply(width_nn_RLCP[,apply(width_nn_RLCP,2,median)!=Inf],2,deviation))
result_h=result_h+c(dev_lm,dev_rf,dev_nn)
}
result_rand[,i]=result_h/20
end=Sys.time()
print(end-start)
}
split=sample(1:3,n,replace=TRUE,prob=c(1/3,1/3,1/3))
result_split=foreach(l=1:30,.combine=comb_rand,
.packages = c("MASS","parallel","doParallel",
"foreach","mvtnorm","randomForest",
"neuralnet")) %dopar% {
real_RLCP_deviation(h,l,split)
}
#computing deviation of the PI across several random seeds
deviation=function(x){median(abs(x-median(x)))/median(x)}
width_lm_RLCP=result_split[[1]]
width_rf_RLCP=result_split[[2]]
width_nn_RLCP=result_split[[3]]
dev_lm=mean(apply(width_lm_RLCP[,apply(width_lm_RLCP,2,median)!=Inf],2,deviation))
dev_rf=mean(apply(width_rf_RLCP[,apply(width_rf_RLCP,2,median)!=Inf],2,deviation))
dev_nn=mean(apply(width_nn_RLCP[,apply(width_nn_RLCP,2,median)!=Inf],2,deviation))
c(dev_lm,dev_rf,dev_nn)
result_rand=matrix(0,ncol=length(hseq),nrow=3)
for(i in 1:length(hseq)){
h=hseq[i]
print(h)
result_h=rep(0,3)
start=Sys.time()
for(k in 1:20){
split=sample(1:3,n,replace=TRUE,prob=c(1/3,1/3,1/3))
result_split=foreach(l=1:30,.combine=comb_rand,
.packages = c("MASS","parallel","doParallel",
"foreach","mvtnorm","randomForest",
"neuralnet")) %dopar% {
real_RLCP_deviation(h,l,split)
}
#computing deviation of the PI across several random seeds
deviation=function(x){median(abs(x-median(x)))/median(x)}
width_lm_RLCP=result_split[[1]]
width_rf_RLCP=result_split[[2]]
width_nn_RLCP=result_split[[3]]
dev_lm=mean(apply(width_lm_RLCP[,apply(width_lm_RLCP,2,median)!=Inf],2,deviation))
dev_rf=mean(apply(width_rf_RLCP[,apply(width_rf_RLCP,2,median)!=Inf],2,deviation))
dev_nn=mean(apply(width_nn_RLCP[,apply(width_nn_RLCP,2,median)!=Inf],2,deviation))
result_h=result_h+c(dev_lm,dev_rf,dev_nn)
}
result_rand[,i]=result_h/20
end=Sys.time()
print(end-start)
}
stopCluster(cl)
#--------------------------------------------------------------
#------------------------visualization-------------------------
#--------------------------------------------------------------
deviation_real_df=c(result_rand[1,],result_rand[2,],result_rand[3,])
deviation_real_df=cbind(deviation_real_df,rep(hseq,3))
deviation_real_df=cbind(deviation_real_df,rep(c("Linear Model","Random Forest","Neural Net"),each=length(hseq)))
deviation_real_df=as.data.frame(deviation_real_df)
colnames(deviation_real_df)=c("deviation","h","setting")
deviation_real_df$setting=as.factor(deviation_real_df$setting)
deviation_real_df$deviation=as.numeric(deviation_real_df$deviation)
deviation_real_df$h=as.numeric(deviation_real_df$h)
deviation_real=ggplot(deviation_real_df,aes(x=h,y=deviation,linetype=setting))+
geom_line()+geom_point()+
scale_linetype_manual(values=c("Linear Model"="dashed","Random Forest"="longdash","Neural Net"="dotdash"))+
labs(x="Bandwidth h",y=expression(D(h)),linetype="Base Method")+
ggtitle("Deviation D(h) of RLCP in real data setting")+
theme(axis.title = element_text(size = 16),
plot.title = element_text(hjust = 0.5,size=16),
legend.position = "bottom",
legend.text = element_text(size=14))
gridExtra::grid.arrange(deviation_simul,deviation_real,ncol=2)
deviation_real
deviation_real=ggplot(deviation_real_df,aes(x=h,y=deviation,linetype=setting))+
geom_line()+geom_point()+
scale_linetype_manual(values=c("Linear Model"="dashed","Random Forest"="dotted","Neural Net"="dotdash"))+
labs(x="Bandwidth h",y=expression(D(h)),linetype="Base Method")+
ggtitle("Deviation D(h) of RLCP in real data setting")+
theme(axis.title = element_text(size = 16),
plot.title = element_text(hjust = 0.5,size=16),
legend.position = "bottom",
legend.text = element_text(size=14))
deviation_real
#--------------------------------------------------------------
#---------------------------visualization----------------------
#--------------------------------------------------------------
deviation_est=read.csv("../results/simul_deviation_estimates.csv")[,-1]
deviation_simul_df=c(unlist(deviation_est[1,]),unlist(deviation_est[2,]))
deviation_simul_df=cbind(deviation_simul_df,rep(hseq,2))
deviation_simul_df=cbind(deviation_simul_df,rep(c(1,2),each=length(hseq)))
hseq=seq(0.1,2.1,by=0.2)
deviation_simul_df=c(unlist(deviation_est[1,]),unlist(deviation_est[2,]))
deviation_simul_df=cbind(deviation_simul_df,rep(hseq,2))
deviation_simul_df=cbind(deviation_simul_df,rep(c(1,2),each=length(hseq)))
deviation_simul_df=as.data.frame(deviation_simul_df)
colnames(deviation_simul_df)=c("deviation","h","setting")
deviation_simul_df$setting=as.factor(deviation_simul_df$setting)
deviation_simul_df$deviation=as.numeric(deviation_simul_df$deviation)
deviation_simul_df$h=as.numeric(deviation_simul_df$h)
deviation_simul=ggplot(deviation_simul_df,aes(x=h,y=deviation,linetype=setting))+
geom_line()+geom_point()+
scale_linetype_manual(values=c("1"="dotted","2"="dashed"))+
labs(x="Bandwidth h",y=expression(D(h)),linetype="Setting")+
ggtitle("Deviation D(h) of RLCP in simulation settings")+
theme(axis.title = element_text(size = 16),
plot.title = element_text(hjust = 0.5,size=16),
legend.position = "bottom",
legend.text = element_text(size=14))
deviation_simul
pdf(file = "../results/RLCP_deviation.pdf",width = 13.5, height = 5)
gridExtra::grid.arrange(deviation_simul,deviation_real,ncol=2)
dev.off()
pdf(file = "../results/figures/RLCP_deviation.pdf",width = 13.5, height = 5)
gridExtra::grid.arrange(deviation_simul,deviation_real,ncol=2)
dev.off()
