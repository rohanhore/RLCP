xtest=Xtest[i,];test_score=scores_test[i]
xtilde_test=xtest
xtilde_test[c(1,3)]=xtest[c(1,3)]+runif(2,min=-h,max=h)
cov_data=rbind(Xcalib,xtest)
weights=apply(abs(sweep(cov_data,2,as.numeric(xtilde_test),"-")),1,FUN=function(x) all(x<=c(h,0,h,0))+0)
result=smoothed_weighted_quantile(scores_unique,alpha,weights,indices)
threshold[i]=result[1]
closed=result[2]
coverage[i]=(test_score<threshold[i])+0
if(closed==TRUE){coverage[i]=(test_score<=threshold[i])+0}
}
return(cbind(coverage,threshold))
}
#--------------------------------------------------------------
#---------------computing deviation of RLCP PI-----------------
#--------------------------------------------------------------
real_RLCP_deviation=function(h,k,split){
train_data=data[split==1,];ntrain=dim(train_data)[1]
calib_data=data[split==2,];ncalib=dim(calib_data)[1]
test_data=data[split==3,];ntest=dim(test_data)[1]
train_scaled_data=scaled_data[split==1,]
calib_scaled_data=scaled_data[split==2,]
test_scaled_data=scaled_data[split==3,]
#------------learning score on train split-------------------------
Xcalib=calib_data[,1:4];Xcalib[,2]=as.numeric(Xcalib[,2]);Xcalib[,4]=as.numeric(Xcalib[,4])
Xtest=test_data[,1:4];Xtest[,2]=as.numeric(Xtest[,2]);Xtest[,4]=as.numeric(Xtest[,4])
#---linear model---------
model_lm=lm(charges~.,data=train_data)
predict_lm_test=predict(model_lm,newdata=test_data)
scores_lm_calib=abs(calib_data$charges-predict.lm(model_lm,calib_data))
scores_lm_test=abs(test_data$charges-predict.lm(model_lm,test_data))
result_lm_RLCP=RLCP_real(Xcalib, scores_lm_calib,Xtest,scores_lm_test,h,0.1)
#result_lm_RLCP[result_lm_RLCP[,2]==Inf,2]=scores_lm_calib
width_lm_RLCP=2*result_lm_RLCP[,2]
#----random forest----------
model_rf=randomForest(charges ~ .,data=train_data)
predict_rf_test=predict(model_rf,newdata=test_data)
scores_rf_calib=abs(calib_data$charges-predict(model_rf,calib_data))
scores_rf_test=abs(test_data$charges-predict(model_rf,test_data))
result_rf_RLCP=RLCP_real(Xcalib, scores_rf_calib,Xtest,scores_rf_test,h,0.1)
width_rf_RLCP=2*result_rf_RLCP[,2]
#----------neural net--------------------
model_nn=neuralnet(charges~.,data = train_scaled_data, hidden = c(5, 3),
threshold=0.05,linear.output = TRUE)
predict_nn_calib=compute(model_nn,calib_scaled_data[,1:6])$net.result*
(max_charge-min_charge)+min_charge
predict_nn_test=compute(model_nn,test_scaled_data[,1:6])$net.result*
(max_charge-min_charge)+min_charge
scores_nn_calib=abs(calib_data$charges-predict_nn_calib)
scores_nn_test=abs(test_data$charges-predict_nn_test)
result_nn_RLCP=RLCP_real(Xcalib,scores_nn_calib,Xtest,scores_nn_test,h,0.1)
width_nn_RLCP=as.vector(2*result_nn_RLCP[,2])
return(list(width_lm_RLCP,width_rf_RLCP,width_nn_RLCP))
}
real_RLCP_deviation(h,l,split)
h=2
l=1
split=sample(1:3,n,replace=TRUE,prob=c(1/3,1/3,1/3))
n
real_RLCP_deviation(h,l,split)
train_data=data[split==1,];ntrain=dim(train_data)[1]
calib_data=data[split==2,];ncalib=dim(calib_data)[1]
test_data=data[split==3,];ntest=dim(test_data)[1]
train_scaled_data=scaled_data[split==1,]
calib_scaled_data=scaled_data[split==2,]
test_scaled_data=scaled_data[split==3,]
#------------learning score on train split-------------------------
Xcalib=calib_data[,1:4];Xcalib[,2]=as.numeric(Xcalib[,2]);Xcalib[,4]=as.numeric(Xcalib[,4])
Xtest=test_data[,1:4];Xtest[,2]=as.numeric(Xtest[,2]);Xtest[,4]=as.numeric(Xtest[,4])
#---linear model---------
model_lm=lm(charges~.,data=train_data)
predict_lm_test=predict(model_lm,newdata=test_data)
scores_lm_calib=abs(calib_data$charges-predict.lm(model_lm,calib_data))
scores_lm_test=abs(test_data$charges-predict.lm(model_lm,test_data))
result_lm_RLCP=RLCP_real(Xcalib, scores_lm_calib,Xtest,scores_lm_test,h,0.1)
#result_lm_RLCP[result_lm_RLCP[,2]==Inf,2]=scores_lm_calib
width_lm_RLCP=2*result_lm_RLCP[,2]
#----random forest----------
model_rf=randomForest(charges ~ .,data=train_data)
width_lm_RLCP
#----------neural net--------------------
model_nn=neuralnet(charges~.,data = train_scaled_data, hidden = c(5, 3),
threshold=0.05,linear.output = TRUE)
predict_nn_calib=compute(model_nn,calib_scaled_data[,1:6])$net.result*
(max_charge-min_charge)+min_charge
predict_nn_test=compute(model_nn,test_scaled_data[,1:6])$net.result*
(max_charge-min_charge)+min_charge
#----------neural net--------------------
model_nn=neuralnet(charges~.,data = train_scaled_data, hidden = c(5, 3),
threshold=0.05,linear.output = TRUE)
#----------neural net--------------------
model_nn=neuralnet(charges~.,data = train_scaled_data, hidden = c(5, 3),
threshold=0.05,linear.output = TRUE)
predict_nn_calib=neuralnet::compute(model_nn,calib_scaled_data[,1:6])$net.result*
(max_charge-min_charge)+min_charge
predict_nn_test=neuralnet::compute(model_nn,test_scaled_data[,1:6])$net.result*
(max_charge-min_charge)+min_charge
scores_nn_calib=abs(calib_data$charges-predict_nn_calib)
scores_nn_test=abs(test_data$charges-predict_nn_test)
result_nn_RLCP=RLCP_real(Xcalib,scores_nn_calib,Xtest,scores_nn_test,h,0.1)
width_nn_RLCP=as.vector(2*result_nn_RLCP[,2])
width_nn_RLCP
abs(-2)
#--------------------------------------------------------------
#---------------computing deviation of RLCP PI-----------------
#--------------------------------------------------------------
real_RLCP_deviation=function(h,k,split){
train_data=data[split==1,];ntrain=dim(train_data)[1]
calib_data=data[split==2,];ncalib=dim(calib_data)[1]
test_data=data[split==3,];ntest=dim(test_data)[1]
train_scaled_data=scaled_data[split==1,]
calib_scaled_data=scaled_data[split==2,]
test_scaled_data=scaled_data[split==3,]
#------------learning score on train split-------------------------
Xcalib=calib_data[,1:4];Xcalib[,2]=as.numeric(Xcalib[,2]);Xcalib[,4]=as.numeric(Xcalib[,4])
Xtest=test_data[,1:4];Xtest[,2]=as.numeric(Xtest[,2]);Xtest[,4]=as.numeric(Xtest[,4])
#---linear model---------
model_lm=lm(charges~.,data=train_data)
predict_lm_test=predict(model_lm,newdata=test_data)
scores_lm_calib=abs(calib_data$charges-predict.lm(model_lm,calib_data))
scores_lm_test=abs(test_data$charges-predict.lm(model_lm,test_data))
result_lm_RLCP=RLCP_real(Xcalib, scores_lm_calib,Xtest,scores_lm_test,h,0.1)
#result_lm_RLCP[result_lm_RLCP[,2]==Inf,2]=scores_lm_calib
width_lm_RLCP=2*abs(result_lm_RLCP[,2])
#----random forest----------
model_rf=randomForest(charges ~ .,data=train_data)
predict_rf_test=predict(model_rf,newdata=test_data)
scores_rf_calib=abs(calib_data$charges-predict(model_rf,calib_data))
scores_rf_test=abs(test_data$charges-predict(model_rf,test_data))
result_rf_RLCP=RLCP_real(Xcalib, scores_rf_calib,Xtest,scores_rf_test,h,0.1)
width_rf_RLCP=2*abs(result_rf_RLCP[,2])
#----------neural net--------------------
model_nn=neuralnet(charges~.,data = train_scaled_data, hidden = c(5, 3),
threshold=0.05,linear.output = TRUE)
predict_nn_calib=neuralnet::compute(model_nn,calib_scaled_data[,1:6])$net.result*
(max_charge-min_charge)+min_charge
predict_nn_test=neuralnet::compute(model_nn,test_scaled_data[,1:6])$net.result*
(max_charge-min_charge)+min_charge
scores_nn_calib=abs(calib_data$charges-predict_nn_calib)
scores_nn_test=abs(test_data$charges-predict_nn_test)
result_nn_RLCP=RLCP_real(Xcalib,scores_nn_calib,Xtest,scores_nn_test,h,0.1)
width_nn_RLCP=as.vector(2*abs(result_nn_RLCP[,2]))
return(list(width_lm_RLCP,width_rf_RLCP,width_nn_RLCP))
}
#--------------------------------------------------------------
#----------------------experimental results--------------------
#--------------------------------------------------------------
library(doParallel)
numcores=detectCores()
cl=makeCluster(numcores)
registerDoParallel(cl)
#bandwidth choices
hseq=2:8
comb_rand=function(x,y){return(list(rbind(x[[1]],y[[1]]),rbind(x[[2]],y[[2]]),rbind(x[[3]],y[[3]])))}
result_rand=matrix(0,ncol=length(hseq),nrow=3)
for(i in 1:length(hseq)){
h=hseq[i]
print(h)
result_h=rep(0,3)
start=Sys.time()
for(k in 1:20){
split=sample(1:3,n,replace=TRUE,prob=c(1/3,1/3,1/3))
result_split=foreach(l=1:30,.combine=comb_rand,
.packages = c("MASS","parallel","doParallel",
"foreach","mvtnorm","randomForest",
"neuralnet")) %dopar% {
real_RLCP_deviation(h,l,split)
}
#computing deviation of the PI across several random seeds
deviation=function(x){median(abs(x-median(x)))/median(x)}
width_lm_RLCP=result_split[[1]]
width_rf_RLCP=result_split[[2]]
width_nn_RLCP=result_split[[3]]
dev_lm=mean(apply(width_lm_RLCP[,apply(width_lm_RLCP,2,median)!=Inf],2,deviation))
dev_rf=mean(apply(width_rf_RLCP[,apply(width_rf_RLCP,2,median)!=Inf],2,deviation))
dev_nn=mean(apply(width_nn_RLCP[,apply(width_nn_RLCP,2,median)!=Inf],2,deviation))
result_h=result_h+c(dev_lm,dev_rf,dev_nn)
}
result_rand[,i]=result_h/20
end=Sys.time()
print(end-start)
}
split=sample(1:3,n,replace=TRUE,prob=c(1/3,1/3,1/3))
result_split=foreach(l=1:30,.combine=comb_rand,
.packages = c("MASS","parallel","doParallel",
"foreach","mvtnorm","randomForest",
"neuralnet")) %dopar% {
real_RLCP_deviation(h,l,split)
}
#computing deviation of the PI across several random seeds
deviation=function(x){median(abs(x-median(x)))/median(x)}
width_lm_RLCP=result_split[[1]]
width_rf_RLCP=result_split[[2]]
width_nn_RLCP=result_split[[3]]
dev_lm=mean(apply(width_lm_RLCP[,apply(width_lm_RLCP,2,median)!=Inf],2,deviation))
dev_rf=mean(apply(width_rf_RLCP[,apply(width_rf_RLCP,2,median)!=Inf],2,deviation))
dev_nn=mean(apply(width_nn_RLCP[,apply(width_nn_RLCP,2,median)!=Inf],2,deviation))
c(dev_lm,dev_rf,dev_nn)
result_rand=matrix(0,ncol=length(hseq),nrow=3)
for(i in 1:length(hseq)){
h=hseq[i]
print(h)
result_h=rep(0,3)
start=Sys.time()
for(k in 1:20){
split=sample(1:3,n,replace=TRUE,prob=c(1/3,1/3,1/3))
result_split=foreach(l=1:30,.combine=comb_rand,
.packages = c("MASS","parallel","doParallel",
"foreach","mvtnorm","randomForest",
"neuralnet")) %dopar% {
real_RLCP_deviation(h,l,split)
}
#computing deviation of the PI across several random seeds
deviation=function(x){median(abs(x-median(x)))/median(x)}
width_lm_RLCP=result_split[[1]]
width_rf_RLCP=result_split[[2]]
width_nn_RLCP=result_split[[3]]
dev_lm=mean(apply(width_lm_RLCP[,apply(width_lm_RLCP,2,median)!=Inf],2,deviation))
dev_rf=mean(apply(width_rf_RLCP[,apply(width_rf_RLCP,2,median)!=Inf],2,deviation))
dev_nn=mean(apply(width_nn_RLCP[,apply(width_nn_RLCP,2,median)!=Inf],2,deviation))
result_h=result_h+c(dev_lm,dev_rf,dev_nn)
}
result_rand[,i]=result_h/20
end=Sys.time()
print(end-start)
}
stopCluster(cl)
#--------------------------------------------------------------
#------------------------visualization-------------------------
#--------------------------------------------------------------
deviation_real_df=c(result_rand[1,],result_rand[2,],result_rand[3,])
deviation_real_df=cbind(deviation_real_df,rep(hseq,3))
deviation_real_df=cbind(deviation_real_df,rep(c("Linear Model","Random Forest","Neural Net"),each=length(hseq)))
deviation_real_df=as.data.frame(deviation_real_df)
colnames(deviation_real_df)=c("deviation","h","setting")
deviation_real_df$setting=as.factor(deviation_real_df$setting)
deviation_real_df$deviation=as.numeric(deviation_real_df$deviation)
deviation_real_df$h=as.numeric(deviation_real_df$h)
deviation_real=ggplot(deviation_real_df,aes(x=h,y=deviation,linetype=setting))+
geom_line()+geom_point()+
scale_linetype_manual(values=c("Linear Model"="dashed","Random Forest"="longdash","Neural Net"="dotdash"))+
labs(x="Bandwidth h",y=expression(D(h)),linetype="Base Method")+
ggtitle("Deviation D(h) of RLCP in real data setting")+
theme(axis.title = element_text(size = 16),
plot.title = element_text(hjust = 0.5,size=16),
legend.position = "bottom",
legend.text = element_text(size=14))
gridExtra::grid.arrange(deviation_simul,deviation_real,ncol=2)
deviation_real
deviation_real=ggplot(deviation_real_df,aes(x=h,y=deviation,linetype=setting))+
geom_line()+geom_point()+
scale_linetype_manual(values=c("Linear Model"="dashed","Random Forest"="dotted","Neural Net"="dotdash"))+
labs(x="Bandwidth h",y=expression(D(h)),linetype="Base Method")+
ggtitle("Deviation D(h) of RLCP in real data setting")+
theme(axis.title = element_text(size = 16),
plot.title = element_text(hjust = 0.5,size=16),
legend.position = "bottom",
legend.text = element_text(size=14))
deviation_real
#--------------------------------------------------------------
#---------------------------visualization----------------------
#--------------------------------------------------------------
deviation_est=read.csv("../results/simul_deviation_estimates.csv")[,-1]
deviation_simul_df=c(unlist(deviation_est[1,]),unlist(deviation_est[2,]))
deviation_simul_df=cbind(deviation_simul_df,rep(hseq,2))
deviation_simul_df=cbind(deviation_simul_df,rep(c(1,2),each=length(hseq)))
hseq=seq(0.1,2.1,by=0.2)
deviation_simul_df=c(unlist(deviation_est[1,]),unlist(deviation_est[2,]))
deviation_simul_df=cbind(deviation_simul_df,rep(hseq,2))
deviation_simul_df=cbind(deviation_simul_df,rep(c(1,2),each=length(hseq)))
deviation_simul_df=as.data.frame(deviation_simul_df)
colnames(deviation_simul_df)=c("deviation","h","setting")
deviation_simul_df$setting=as.factor(deviation_simul_df$setting)
deviation_simul_df$deviation=as.numeric(deviation_simul_df$deviation)
deviation_simul_df$h=as.numeric(deviation_simul_df$h)
deviation_simul=ggplot(deviation_simul_df,aes(x=h,y=deviation,linetype=setting))+
geom_line()+geom_point()+
scale_linetype_manual(values=c("1"="dotted","2"="dashed"))+
labs(x="Bandwidth h",y=expression(D(h)),linetype="Setting")+
ggtitle("Deviation D(h) of RLCP in simulation settings")+
theme(axis.title = element_text(size = 16),
plot.title = element_text(hjust = 0.5,size=16),
legend.position = "bottom",
legend.text = element_text(size=14))
deviation_simul
pdf(file = "../results/RLCP_deviation.pdf",width = 13.5, height = 5)
gridExtra::grid.arrange(deviation_simul,deviation_real,ncol=2)
dev.off()
pdf(file = "../results/figures/RLCP_deviation.pdf",width = 13.5, height = 5)
gridExtra::grid.arrange(deviation_simul,deviation_real,ncol=2)
dev.off()
deviation_real
deviation_real=ggplot(deviation_real_df,aes(x=h,y=deviation,linetype=setting))+
geom_line()+geom_point()+
scale_linetype_manual(values=c("Linear Model"="dashed","Random Forest"="dotted","Neural Net"="dotdash"))+
labs(x="Bandwidth h",y=expression(D(h)),linetype="Base Method")+
ggtitle("Deviation D(h) of RLCP in real data setting")+
theme(axis.title = element_text(size = 16),
axis.text=element_text(size=16),
plot.title = element_text(hjust = 0.5,size=16),
legend.position = "bottom",
legend.text = element_text(size=14))
library(ggplot2)
deviation_real=ggplot(deviation_real_df,aes(x=h,y=deviation,linetype=setting))+
geom_line()+geom_point()+
scale_linetype_manual(values=c("Linear Model"="dashed","Random Forest"="dotted","Neural Net"="dotdash"))+
labs(x="Bandwidth h",y=expression(D(h)),linetype="Base Method")+
ggtitle("Deviation D(h) of RLCP in real data setting")+
theme(axis.title = element_text(size = 16),
axis.text=element_text(size=16),
plot.title = element_text(hjust = 0.5,size=16),
legend.position = "bottom",
legend.text = element_text(size=14))
pdf(file = "../results/figures/RLCP_deviation.pdf",width = 13.5, height = 5)
gridExtra::grid.arrange(deviation_simul,deviation_real,ncol=2)
dev.off()
deviation_simul=ggplot(deviation_simul_df,aes(x=h,y=deviation,linetype=setting))+
geom_line()+geom_point()+
scale_linetype_manual(values=c("1"="dotted","2"="dashed"))+
labs(x="Bandwidth h",y=expression(D(h)),linetype="Setting")+
ggtitle("Deviation D(h) of RLCP in simulation settings")+
theme(axis.title = element_text(size = 16),
axis.text = element_text(size=16),
plot.title = element_text(hjust = 0.5,size=16),
legend.position = "bottom",
legend.text = element_text(size=14))
deviation_simul
pdf(file = "../results/figures/RLCP_deviation.pdf",width = 13.5, height = 5)
gridExtra::grid.arrange(deviation_simul,deviation_real,ncol=2)
dev.off()
grid.arrange(plot3,plot4,ncol=2,widths=c(2.6,3))
suppressPackageStartupMessages(library(gridExtra))
grid.arrange(plot3,plot4,ncol=2,widths=c(2.6,3))
plot4=ggplot(plot_result[plot_result$h %in% c(2,6),], aes(x = bmi, y = coverage,color=CP_method)) +
geom_line() +
geom_hline(yintercept=0.9,linetype="dashed")+
xlab("BMI quantile")+
scale_color_manual(values=c("RLCP"="maroon","calLCP"="gold3","baseLCP"="blue"))+
facet_grid(h~ `base method` ,labeller=label_bquote(cols = .(`base method`),rows= h ==.(h)))+
theme(axis.title = element_text(size = 14),
axis.text=element_text(size=14),
plot.title = element_text(hjust = 0.5,size=14),
legend.position = "bottom",
legend.text = element_text(size=14))+
labs(color="Method",x="BMI Quantile",y="Local Coverage")
plot4
plot3=ggplot(plot_result[plot_result$h %in% c(2,6),], aes(x = CP_method, y = coverage,group=smoker,
fill=smoker)) +
geom_col(position='dodge',width=0.5) +
coord_cartesian(ylim=c(0.8,1))+
xlab("LCP method")+
scale_fill_discrete(labels=c("0"="no","1"="yes"))+
geom_hline(yintercept=0.9,linetype="dashed")+
facet_grid(h~`base method`,labeller = label_bquote(cols = .(`base method`),rows= h ==.(h)))+
theme(axis.title = element_text(size = 14),
axis.text=element_text(size=14),
plot.title = element_text(hjust = 0.5,size=14),
legend.position = "bottom",
legend.text = element_text(size=14))+
labs(fill="Smoker",x="Method",y="Coverage")
plot3
#---------------across smoking groups------------------
plot_result=matrix(0,ncol=5,nrow=2*9*length(hseq))
for(i in 1:length(hseq)){
id=(2*9*(i-1)+1):(2*9*i)
res=stack(as.data.frame(real_result[[i]][[4]]))
plot_result[id,1]=res[,1]
plot_result[id,2]=rep(rep(c("RLCP","calLCP","baseLCP"),each=2),3)
plot_result[id,3]=rep(c("Linear Model","Random Forest","Neural Net"),each=2*3)
plot_result[id,4]=rep(c(0,1),9)
plot_result[id,5]=hseq[i]
}
#bandwidth choices
hseq=2:8
#---------------across smoking groups------------------
plot_result=matrix(0,ncol=5,nrow=2*9*length(hseq))
for(i in 1:length(hseq)){
id=(2*9*(i-1)+1):(2*9*i)
res=stack(as.data.frame(real_result[[i]][[4]]))
plot_result[id,1]=res[,1]
plot_result[id,2]=rep(rep(c("RLCP","calLCP","baseLCP"),each=2),3)
plot_result[id,3]=rep(c("Linear Model","Random Forest","Neural Net"),each=2*3)
plot_result[id,4]=rep(c(0,1),9)
plot_result[id,5]=hseq[i]
}
plot_result=as.data.frame(plot_result)
colnames(plot_result)=c("coverage","CP_method","base method","smoker","h")
plot_result$coverage=as.numeric(plot_result$coverage)
plot_result$h=as.numeric(plot_result$h)
plot_result$CP_method=factor(plot_result$CP_method,level=c('baseLCP','calLCP','RLCP'))
plot3=ggplot(plot_result[plot_result$h %in% c(2,6),], aes(x = CP_method, y = coverage,group=smoker,
fill=smoker)) +
geom_col(position='dodge',width=0.5) +
coord_cartesian(ylim=c(0.8,1))+
xlab("LCP method")+
scale_fill_discrete(labels=c("0"="no","1"="yes"))+
geom_hline(yintercept=0.9,linetype="dashed")+
facet_grid(h~`base method`,labeller = label_bquote(cols = .(`base method`),rows= h ==.(h)))+
theme(axis.title = element_text(size = 14),
axis.text=element_text(size=14),
plot.title = element_text(hjust = 0.5,size=14),
legend.position = "bottom",
legend.text = element_text(size=14))+
labs(fill="Smoker",x="Method",y="Coverage")
plot3
pdf(file = "../results/figures/realdata_conditional_results.pdf",width = 13, height = 5)
grid.arrange(plot3,plot4,ncol=2,widths=c(2.6,3))
dev.off()
pdf(file = "../results/figures/realdata_conditional_results.pdf",width = 15, height = 5)
grid.arrange(plot3,plot4,ncol=2,widths=c(2.6,3))
dev.off()
plot3=ggplot(plot_result[plot_result$h %in% c(2,6),], aes(x = CP_method, y = coverage,group=smoker,
fill=smoker)) +
geom_col(position='dodge',width=0.5) +
coord_cartesian(ylim=c(0.8,1))+
xlab("LCP method")+
scale_fill_discrete(labels=c("0"="no","1"="yes"))+
geom_hline(yintercept=0.9,linetype="dashed")+
facet_grid(h~`base method`,labeller = label_bquote(cols = .(`base method`),rows= h ==.(h)))+
theme(axis.title = element_text(size = 14),
axis.text=element_text(size=12),
plot.title = element_text(hjust = 0.5,size=14),
legend.position = "bottom",
legend.text = element_text(size=14))+
labs(fill="Smoker",x="Method",y="Coverage")
pdf(file = "../results/figures/realdata_conditional_results.pdf",width = 15, height = 5)
grid.arrange(plot3,plot4,ncol=2,widths=c(2.6,3))
dev.off()
pdf(file = "../results/figures/realdata_conditional_results.pdf",width = 16, height = 5)
grid.arrange(plot3,plot4,ncol=2,widths=c(2.6,3))
dev.off()
plot3=ggplot(plot_result[plot_result$h %in% c(2,6),], aes(x = CP_method, y = coverage,group=smoker,
fill=smoker)) +
geom_col(position='dodge',width=0.5) +
coord_cartesian(ylim=c(0.8,1))+
xlab("LCP method")+
scale_fill_discrete(labels=c("0"="no","1"="yes"))+
geom_hline(yintercept=0.9,linetype="dashed")+
facet_grid(h~`base method`,labeller = label_bquote(cols = .(`base method`),rows= h ==.(h)))+
theme(axis.title = element_text(size = 14),
axis.text=element_text(size=12),
plot.title = element_text(hjust = 0.5,size=14),
legend.position = "bottom",
legend.text = element_text(size=14),
strip.text = element_text(size=14))+
labs(fill="Smoker",x="Method",y="Coverage")
plot3
#-------------across BMI bins-------------------------
bmi_quantiles=seq(0.125,0.875,by=0.01);len_q=length(bmi_quantiles)
plot_result=matrix(0,ncol=5,nrow=len_q*9*length(hseq))
for(i in 1:length(hseq)){
id=(len_q*9*(i-1)+1):(len_q*9*i)
res=stack(as.data.frame(real_result[[i]][[3]]))
plot_result[id,1]=res[,1]
plot_result[id,2]=rep(rep(c("RLCP","calLCP","baseLCP"),each=len_q),3)
plot_result[id,3]=rep(c("Linear Model","Random Forest","Neural Net"),each=len_q*3)
plot_result[id,4]=rep(bmi_quantiles,9)
plot_result[id,5]=hseq[i]
}
plot_result=as.data.frame(plot_result)
colnames(plot_result)=c("coverage","CP_method","base method","bmi","h")
plot_result$coverage=as.numeric(plot_result$coverage)
plot_result$bmi=as.numeric(plot_result$bmi)
plot_result$h=as.numeric(plot_result$h)
plot_result$CP_method=factor(plot_result$CP_method,level=c('baseLCP','calLCP','RLCP'))
plot4=ggplot(plot_result[plot_result$h %in% c(2,6),], aes(x = bmi, y = coverage,color=CP_method)) +
geom_line() +
geom_hline(yintercept=0.9,linetype="dashed")+
xlab("BMI quantile")+
scale_color_manual(values=c("RLCP"="maroon","calLCP"="gold3","baseLCP"="blue"))+
facet_grid(h~ `base method` ,labeller=label_bquote(cols = .(`base method`),rows= h ==.(h)))+
theme(axis.title = element_text(size = 14),
axis.text=element_text(size=14),
plot.title = element_text(hjust = 0.5,size=14),
legend.position = "bottom",
legend.text = element_text(size=14),
strip.text = element_text(size=14))+
labs(color="Method",x="BMI Quantile",y="Local Coverage")
pdf(file = "../results/figures/realdata_conditional_results.pdf",width = 16, height = 5)
grid.arrange(plot3,plot4,ncol=2,widths=c(2.6,3))
dev.off()
pdf(file = "../results/figures/realdata_conditional_results.eps",width = 16, height = 5)
grid.arrange(plot3,plot4,ncol=2,widths=c(2.6,3))
suppressPackageStartupMessages(library(gridExtra))
suppressPackageStartupMessages(library(ggplot2))
grid.arrange(plot3,plot4,ncol=2,widths=c(2.6,3))
dev.off()
setEPS()
postscript(file = "../results/figures/realdata_conditional_results.pdf",width = 16, height = 5)
grid.arrange(plot3,plot4,ncol=2,widths=c(2.6,3))
dev.off()
pdf(file = "../results/figures/realdata_conditional_results.pdf",width = 16, height = 5)
grid.arrange(plot3,plot4,ncol=2,widths=c(2.6,3))
dev.off()
setEPS()
postscript(file = "../results/figures/realdata_conditional_results.eps",width = 16, height = 5)
grid.arrange(plot3,plot4,ncol=2,widths=c(2.6,3))
dev.off()
setEPS()
postscript(file = "../results/figures/realdata_conditional_results.eps",width = 16, height = 8)
grid.arrange(plot3,plot4,ncol=2,widths=c(2.6,3))
dev.off()
postscript(file = "../results/figures/realdata_conditional_results.eps",width = 15, height = 7)
grid.arrange(plot3,plot4,ncol=2,widths=c(2.6,3))
dev.off()
setEPS()
postscript(file = "../results/figures/realdata_marginal_results.eps",width = 10, height = 4)
grid.arrange(plot1,plot2,ncol=2,widths=c(2.6,3))
dev.off()
postscript(file = "../results/figures/realdata_marginal_results.eps",width = 12, height = 5)
grid.arrange(plot1,plot2,ncol=2,widths=c(2.6,3))
dev.off()
